{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spam = pd.read_csv(\"spam.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spam[\"target\"] = np.where(spam[\"target\"] == \"spam\", 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  Go until jurong point, crazy.. Available only ...       0\n",
       "1                      Ok lar... Joking wif u oni...       0\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...       1\n",
       "3  U dun say so early hor... U c already then say...       0\n",
       "4  Nah I don't think he goes to usf, he lives aro...       0\n",
       "5  FreeMsg Hey there darling it's been 3 week's n...       1\n",
       "6  Even my brother is not like to speak with me. ...       0\n",
       "7  As per your request 'Melle Melle (Oru Minnamin...       0\n",
       "8  WINNER!! As a valued network customer you have...       1\n",
       "9  Had your mobile 11 months or more? U R entitle...       1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n"
     ]
    }
   ],
   "source": [
    "print spam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(spam[\"text\"], spam[\"target\"], random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of documents that are spam: 0.134063173008\n"
     ]
    }
   ],
   "source": [
    "print \"Percent of documents that are spam:\", np.mean(spam[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer().fit(spam[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'hypotheticalhuagauahahuagahyuhagga'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = np.array(vect.get_feature_names())\n",
    "sorted(tokens, key=lambda x: len(x), reverse=True)[0] #longest token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer().fit(xtrain)\n",
    "xtrain_vect = vect.transform(xtrain)\n",
    "nb = MultinomialNB()\n",
    "nb.fit(xtrain_vect, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7354\n"
     ]
    }
   ],
   "source": [
    "print len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes AUC: 0.958136682342\n"
     ]
    }
   ],
   "source": [
    "predsNB = nb.predict(vect.transform(xtest))\n",
    "print \"Naive Bayes AUC:\", roc_auc_score(ytest, predsNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7354\n"
     ]
    }
   ],
   "source": [
    "vect = TfidfVectorizer().fit(xtrain)\n",
    "print len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain_vector = vect.transform(xtrain)\n",
    "feature_names = np.array(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_tfidf = xtrain_vector.max(0).toarray()[0].argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest tfidf: [u'sympathetic' u'healer' u'aaniye' u'dependable' u'companion' u'listener'\n",
      " u'athletic' u'exterminator' u'psychiatrist' u'pest']\n",
      "Largest tfidf: [u'146tf150p' u'havent' u'home' u'okie' u'thanx' u'er' u'anything' u'lei'\n",
      " u'nite' u'yup']\n"
     ]
    }
   ],
   "source": [
    "print \"Smallest tfidf:\", feature_names[sorted_tfidf[:10]]\n",
    "print \"Largest tfidf:\", feature_names[sorted_tfidf[:-11:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_feature(X, feature_to_add):\n",
    "    \"\"\"\n",
    "    Returns sparse feature matrix with added feature.\n",
    "    feature_to_add can also be a list of features.\n",
    "    \"\"\"\n",
    "    from scipy.sparse import csr_matrix, hstack\n",
    "    return hstack([X, csr_matrix(feature_to_add).T], 'csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2295\n"
     ]
    }
   ],
   "source": [
    "vect = TfidfVectorizer(min_df=3).fit(xtrain)\n",
    "print len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.941624365482\n"
     ]
    }
   ],
   "source": [
    "xtrain_vect = vect.transform(xtrain)\n",
    "nb = MultinomialNB(alpha=0.1) #Laplace smoothing parameter = 0.1\n",
    "nb.fit(xtrain_vect, ytrain)\n",
    "preds = nb.predict(vect.transform(xtest))\n",
    "print \"AUC:\", roc_auc_score(ytest, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length spam text: 747.0\n",
      "Average length non-spam text: 4825.0\n"
     ]
    }
   ],
   "source": [
    "print \"Average length spam text:\",np.mean(len(spam[spam[\"target\"] == 1][\"text\"]))\n",
    "print \"Average length non-spam text:\",np.mean(len(spam[spam[\"target\"] == 0][\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1468\n"
     ]
    }
   ],
   "source": [
    "vect = TfidfVectorizer(min_df=5).fit(xtrain)\n",
    "print len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xtrain_vect = vect.transform(xtrain)\n",
    "xtrain_vect = add_feature(xtrain_vect, xtrain.apply(lambda x: len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.958136682342\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(C=10000)\n",
    "svc.fit(xtrain_vect, ytrain)\n",
    "xtest_vect = vect.transform(xtest)\n",
    "xtest_vect = add_feature(xtest_vect, xtest.apply(lambda x: len(x)))\n",
    "preds = svc.predict(xtest_vect)\n",
    "print \"AUC:\", roc_auc_score(ytest, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number digits non-spam document: 0.299274611399\n",
      "Average number digits spam document: 15.7590361446\n"
     ]
    }
   ],
   "source": [
    "print \"Average number digits non-spam document:\", np.mean(spam[spam[\"target\"] == 0].text.apply(lambda x: sum([c.isdigit() for c in x])))\n",
    "print \"Average number digits spam document:\", np.mean(spam[spam[\"target\"] == 1].text.apply(lambda x: sum([c.isdigit() for c in x])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3383\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(min_df=5, ngram_range=(1, 3)).fit(xtrain)\n",
    "xtrain_vect = vect.transform(xtrain)\n",
    "xtrain_vect = add_feature(xtrain_vect, xtrain.apply(lambda x: sum([c.isdigit() for c in x])))\n",
    "print len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.968318676468\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(C=100)\n",
    "model.fit(xtrain_vect, ytrain)\n",
    "xtest_vect = vect.transform(xtest)\n",
    "xtest_vect = add_feature(xtest_vect, xtest.apply(lambda x: sum([c.isdigit() for c in x])))\n",
    "preds = model.predict(xtest_vect)\n",
    "print \"AUC:\", roc_auc_score(ytest, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "string = \"$kajflafj#&#*&*#\"\n",
    "print len(re.findall(r\"\\W\", string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average non-word characters non-spam: 17.4864248705\n",
      "Average non-word characters spam: 30.3895582329\n"
     ]
    }
   ],
   "source": [
    "print \"Average non-word characters non-spam:\", np.mean(spam[spam[\"target\"] == 0][\"text\"].apply(lambda x: len(re.findall(r\"\\W\", x))))\n",
    "print \"Average non-word characters spam:\", np.mean(spam[spam[\"target\"] == 1][\"text\"].apply(lambda x: len(re.findall(r\"\\W\", x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2448\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(min_df=5, ngram_range=(2, 5)).fit(xtrain)\n",
    "xtrain_vect = vect.transform(xtrain)\n",
    "xtrain_vect = add_feature(xtrain_vect, xtrain.apply(lambda x: sum([c.isdigit() for c in x])))\n",
    "xtrain_vect = add_feature(xtrain_vect, xtrain.apply(lambda x: len(re.findall(r\"\\W\", x))))\n",
    "print len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.941236015144\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(C=100)\n",
    "model.fit(xtrain_vect, ytrain)\n",
    "xtest_vect = vect.transform(xtest)\n",
    "xtest_vect = add_feature(xtest_vect, xtest.apply(lambda x: sum([c.isdigit() for c in x])))\n",
    "xtest_vect = add_feature(xtest_vect, xtest.apply(lambda x: len(re.findall(r\"\\W\", x))))\n",
    "preds = model.predict(xtest_vect)\n",
    "print \"AUC:\", roc_auc_score(ytest, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
